# -*- coding: utf-8 -*-
"""generate_output_linear_confirmed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eJAU-EP7Jh1-FFDBdSJw8wHZrIJO85Nb
"""

import numpy as np
import pandas as pd
from scipy.signal import savgol_filter
from scipy.interpolate import UnivariateSpline
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.linear_model import Ridge
import math
from fbprophet import Prophet
import matplotlib.pyplot as plt

def getStates():
    ds = pd.read_csv('data/test.csv')
    states = ds['Province_State'][:50].values   
    return states

def distance(x, y, side_check=False):
    if side_check:
        if y > x:
            return 0
    b = y + x
    i = b / 2
    return math.sqrt((x - i)**2 + (y - i)**2)

def all_distance(data, side_check=False):
    rtn = []
    for i in range(len(data)):
        rtn.append(distance(i, data[i], side_check=side_check))
    return rtn

def standardization(data):
    mu = np.mean(data, axis=0)
    sigma = np.std(data, axis=0)
    return (data - mu) / sigma

degree = 3
states = getStates()
start = 137
alpha = .5
window = 15
states2idx = {}
for i in range(len(states)):
    states2idx[states[i]] = i

feature = 'Confirmed'
res = []
total = 0

for i in range(len(states)):
    state = states[i]
    ds = pd.read_csv('data/train.csv')
    ds = ds[ds['Province_State'] == state]
    raw = ds[feature].values
    value = savgol_filter(raw.reshape(-1), window, degree) #smooth data
    
###===================================================================###   
    scale = raw / raw[-1] * 142
    distances = all_distance(scale)
    diff = sum(distances[-30:])
    max_point = distances.index(max(distances))       

    if scale[80] > 100: # Grow too fast, Saturated
        x = [[i] for i in range(142)]
        model = Pipeline([
            ("poly", PolynomialFeatures(degree=1)),
            ("lasso_reg", Ridge(alpha=0)) 
        ])
        model.fit(x[-10:], value[-10:])
        x_test = [[i + 142] for i in range(26)]
        y_hat = model.predict(x_test)
        y_hat = y_hat.reshape(-1,1)
###===================================================================###
    else:
        y = np.array([value[start:]]).reshape(-1, 1)
        x = [[i + start] for i in range(142-start)]
        model = Ridge(alpha=alpha)
        model.fit(x, y)
        x_test = [[i + 142] for i in range(26)]
        y_hat = model.predict(x_test)
        slope = (168 - 142) / (y_hat[-1] - y_hat[0]) * raw[-1] / 142
###===================================================================###
        move_in = pd.read_csv('data/move_in_data.csv')
        move_out = pd.read_csv('data/move_out_data.csv')

        idx = states2idx[state]

        move_in = move_in.iloc[[idx]].values[0][2:]
        move_out = move_out.iloc[[idx]].values[0][2:]

        smooth_move_in = savgol_filter(move_in.reshape(-1), 11, 3)
        smooth_move_out = savgol_filter(move_out.reshape(-1), 11, 3)

        move_diff = move_in - move_out
###===================================================================###
        all_neg = True
        for i in move_diff[-30:]:
            if i > 0:
                all_neg = False
                break
 
        if all_neg and (np.mean(move_diff[-14:]) - np.mean(move_diff[-28:-14]) < 0):# tend to slow down
            move_slope = 14 / np.mean(move_diff[-14:]) - np.mean(move_diff[-28:-14]) / np.mean(move_diff[-14:-7])
            y_hat = (y_hat - y_hat[0]) * (-move_slope) + y_hat[0] # 1 - (1 - |move_slope|)
###===================================================================###        
        all_pos = True    
        for i in move_diff[-30:]:
            if i < 0:
                all_pos = False
                break
 
        if all_pos and (np.mean(move_diff[-14:]) - np.mean(move_diff[-28:-14]) > 0):# tend to speed up
            move_slope = 14 / np.mean(move_diff[-14:]) - np.mean(move_diff[-28:-14]) / np.mean(move_diff[-14:-7])
            y_hat = (y_hat - y_hat[0]) * (2 + move_slope) + y_hat[0] # 1 + (1 - |move_slope|)          
###===================================================================###
        std_move_diff = standardization(move_diff)
        fst_mean = np.mean(std_move_diff[-28:-21])
        snd_mean = np.mean(std_move_diff[-14:-7])
        if abs(fst_mean - snd_mean) > 2: # detect sudden change of mobilility
            value = savgol_filter(value.reshape(-1), window, degree)
            y = np.array([value[start - 7:]]).reshape(-1, 1)
            x = [[i + start - 7] for i in range(142 - start + 7)] # double training set
            model = Ridge(alpha=alpha)
            model.fit(x, y)
            x_test = [[i + 142] for i in range(26)]
            y_hat = model.predict(x_test)    
###===================================================================###        
        state_data = ds[-21:]
        df_date = state_data['Date'].to_frame()
        df_y = state_data[feature].to_frame()
        df = pd.concat([df_y, df_date], axis=1)
        df.columns = ['y', 'ds']
        m = Prophet()
        m.fit(df)
        future = m.make_future_dataframe(periods=26)
        forecast = m.predict(future)
        sesonality = forecast['weekly'].values # extract seasonality from prophet
        sesonality = sesonality
        sesonality = sesonality[-26:].reshape(-1, 1)
        y_hat = y_hat + sesonality # apply seasonality to our result
###===================================================================###        
    res.append(y_hat)

rerange = []
for i in range(len(res[0])):
    for j in range(len(res)):
        rerange.append(res[j][i])
#print(rerange)
df = pd.DataFrame(rerange)
df.to_csv("output-final/{}.csv".format(feature),index=False,sep=',')